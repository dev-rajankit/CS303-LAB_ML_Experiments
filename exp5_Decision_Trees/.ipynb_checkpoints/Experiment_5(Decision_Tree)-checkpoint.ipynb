{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ac26f09-7e8d-43da-99f9-0a7632ab6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier as SklearnDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f6558fd-a87a-473f-9cbf-6ce2c8c2669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Load UCI Adult Dataset ======\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "columns = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "    'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'\n",
    "]\n",
    "\n",
    "data = pd.read_csv(url, names=columns, sep=',\\s*', engine='python', na_values='?')\n",
    "data = data.dropna()  # Remove rows with missing values\n",
    "\n",
    "# Features and target\n",
    "X = data.drop(columns=['income'])\n",
    "y = data['income']\n",
    "\n",
    "# Encode categorical features\n",
    "for col in X.select_dtypes('object').columns:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e8aeee-29f3-4674-a20a-1535e0afc7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (18096, 14) Val: (6033, 14) Test: (6033, 14)\n"
     ]
    }
   ],
   "source": [
    "# ====== Train-Val-Test Split ======\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42)\n",
    "print('Train:', X_train.shape, 'Val:', X_val.shape, 'Test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a55f58-bfdf-4a19-8dbf-e1e616b77ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Decision Tree from Scratch ======\n",
    "class TreeNode:\n",
    "    def __init__(self, depth=0):\n",
    "        self.feature_idx = None\n",
    "        self.threshold = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.is_leaf = False\n",
    "        self.pred_label = None\n",
    "        self.depth = depth\n",
    "\n",
    "class DecisionTreeCustom:\n",
    "    def __init__(self, criterion='gini', max_depth=None, min_samples_split=2):\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "\n",
    "    def _gini_index(self, y):\n",
    "        probs = np.bincount(y) / len(y)\n",
    "        return 1 - np.sum(probs ** 2)\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        probs = np.bincount(y) / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in probs if p > 0])\n",
    "\n",
    "    def _impurity(self, y):\n",
    "        return self._gini_index(y) if self.criterion == 'gini' else self._entropy(y)\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        best_gain, best_feature, best_thresh = 0, None, None\n",
    "        parent_impurity = self._impurity(y)\n",
    "        for col in range(X.shape[1]):\n",
    "            unique_vals = np.unique(X[:, col])\n",
    "            if len(unique_vals) == 1:\n",
    "                continue\n",
    "            thresholds = (unique_vals[:-1] + unique_vals[1:]) / 2\n",
    "            for t in thresholds:\n",
    "                left_y = y[X[:, col] <= t]\n",
    "                right_y = y[X[:, col] > t]\n",
    "                if len(left_y) == 0 or len(right_y) == 0:\n",
    "                    continue\n",
    "                weighted_impurity = (len(left_y) * self._impurity(left_y) + len(right_y) * self._impurity(right_y)) / len(y)\n",
    "                gain = parent_impurity - weighted_impurity\n",
    "                if gain > best_gain:\n",
    "                    best_gain, best_feature, best_thresh = gain, col, t\n",
    "        return best_feature, best_thresh, best_gain\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        node = TreeNode(depth)\n",
    "        if len(np.unique(y)) == 1 or (self.max_depth and depth >= self.max_depth) or len(y) < self.min_samples_split:\n",
    "            node.is_leaf = True\n",
    "            node.pred_label = Counter(y).most_common(1)[0][0]\n",
    "            return node\n",
    "\n",
    "        feat, thr, gain = self._find_best_split(X, y)\n",
    "        if feat is None:\n",
    "            node.is_leaf = True\n",
    "            node.pred_label = Counter(y).most_common(1)[0][0]\n",
    "            return node\n",
    "\n",
    "        node.feature_idx = feat\n",
    "        node.threshold = thr\n",
    "        left_mask = X[:, feat] <= thr\n",
    "        right_mask = X[:, feat] > thr\n",
    "        node.left = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        node.right = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "        return node\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self._build_tree(np.array(X), np.array(y), 0)\n",
    "\n",
    "    def _predict_sample(self, x, node):\n",
    "        if node.is_leaf:\n",
    "            return node.pred_label\n",
    "        if x[node.feature_idx] <= node.threshold:\n",
    "            return self._predict_sample(x, node.left)\n",
    "        else:\n",
    "            return self._predict_sample(x, node.right)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_sample(x, self.root) for x in np.array(X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1cbb803-5da6-4cae-a3e9-3aed948733d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Reduced Error Pruning ======\n",
    "def reduced_error_pruning(tree, X_val, y_val):\n",
    "    best_acc = accuracy_score(y_val, tree.predict(X_val))\n",
    "    improvement = True\n",
    "\n",
    "    def internal_nodes(node):\n",
    "        nodes_list = []\n",
    "        def traverse(n):\n",
    "            if n and not n.is_leaf:\n",
    "                nodes_list.append(n)\n",
    "                traverse(n.left)\n",
    "                traverse(n.right)\n",
    "        traverse(node)\n",
    "        return nodes_list\n",
    "\n",
    "    while improvement:\n",
    "        improvement = False\n",
    "        nodes = internal_nodes(tree.root)\n",
    "        for n in nodes:\n",
    "            backup = (n.feature_idx, n.threshold, n.left, n.right, n.is_leaf, n.pred_label)\n",
    "            n.is_leaf = True\n",
    "            n.left = n.right = None\n",
    "            n.pred_label = Counter(y_train).most_common(1)[0][0]\n",
    "            new_acc = accuracy_score(y_val, tree.predict(X_val))\n",
    "            if new_acc >= best_acc:\n",
    "                best_acc = new_acc\n",
    "                improvement = True\n",
    "            else:\n",
    "                n.feature_idx, n.threshold, n.left, n.right, n.is_leaf, n.pred_label = backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ec5283c-898f-404c-b68c-67b82e1b354f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8545534924845269\n",
      "Val Accuracy: 0.8506547323056523\n",
      "Validation accuracy before pruning: 0.8506547323056523\n",
      "Validation accuracy after pruning: 0.8511519973479198\n"
     ]
    }
   ],
   "source": [
    "# ====== Train & Evaluate ======\n",
    "model_custom = DecisionTreeCustom(criterion='gini', max_depth=6, min_samples_split=5)\n",
    "model_custom.fit(X_train, y_train)\n",
    "\n",
    "print('Train Accuracy:', accuracy_score(y_train, model_custom.predict(X_train)))\n",
    "print('Val Accuracy:', accuracy_score(y_val, model_custom.predict(X_val)))\n",
    "\n",
    "print('Validation accuracy before pruning:', accuracy_score(y_val, model_custom.predict(X_val)))\n",
    "reduced_error_pruning(model_custom, X_val, y_val)\n",
    "print('Validation accuracy after pruning:', accuracy_score(y_val, model_custom.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "098179b4-de46-4d30-9c07-0d31202b2bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Evaluation Function ======\n",
    "def evaluate_model(model, X, y):\n",
    "    preds = model.predict(X)\n",
    "    print(\"Accuracy:\", accuracy_score(y, preds))\n",
    "    print(\"Precision:\", precision_score(y, preds, average='weighted'))\n",
    "    print(\"Recall:\", recall_score(y, preds, average='weighted'))\n",
    "    print(\"F1 Score:\", f1_score(y, preds, average='weighted'))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c50eca0e-6ac1-41e0-abe8-ea128e0d80d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Depth = 2 ---\n",
      "Accuracy: 0.8219791148682247\n",
      "Precision: 0.8138132099089248\n",
      "Recall: 0.8219791148682247\n",
      "F1 Score: 0.8023114355673043\n",
      "Confusion Matrix:\n",
      " [[4332  199]\n",
      " [ 875  627]]\n",
      "\n",
      "--- Depth = 4 ---\n",
      "Accuracy: 0.8478368970661363\n",
      "Precision: 0.8414250499153328\n",
      "Recall: 0.8478368970661363\n",
      "F1 Score: 0.8381950700834554\n",
      "Confusion Matrix:\n",
      " [[4294  237]\n",
      " [ 681  821]]\n",
      "\n",
      "--- Depth = 6 ---\n",
      "Accuracy: 0.8506547323056523\n",
      "Precision: 0.8442326744157831\n",
      "Recall: 0.8506547323056523\n",
      "F1 Score: 0.8429707254503235\n",
      "Confusion Matrix:\n",
      " [[4268  263]\n",
      " [ 638  864]]\n",
      "\n",
      "--- Depth = None ---\n",
      "Accuracy: 0.8092159787833582\n",
      "Precision: 0.8114496068372945\n",
      "Recall: 0.8092159787833582\n",
      "F1 Score: 0.810268552844933\n",
      "Confusion Matrix:\n",
      " [[3930  601]\n",
      " [ 550  952]]\n"
     ]
    }
   ],
   "source": [
    "# Compare different depths\n",
    "for d in [2, 4, 6, None]:\n",
    "    print(f\"\\n--- Depth = {d} ---\")\n",
    "    m = DecisionTreeCustom(max_depth=d, min_samples_split=5)\n",
    "    m.fit(X_train, y_train)\n",
    "    evaluate_model(m, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "224cb333-164c-4df0-9016-09d7cd8bf962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Criterion = gini ---\n",
      "Accuracy: 0.8508204873197415\n",
      "Precision: 0.8444173850022059\n",
      "Recall: 0.8508204873197415\n",
      "F1 Score: 0.8431698246308788\n",
      "Confusion Matrix:\n",
      " [[4268  263]\n",
      " [ 637  865]]\n",
      "\n",
      "--- Criterion = entropy ---\n",
      "Accuracy: 0.8508204873197415\n",
      "Precision: 0.8452931458381515\n",
      "Recall: 0.8508204873197415\n",
      "F1 Score: 0.840608636904044\n",
      "Confusion Matrix:\n",
      " [[4317  214]\n",
      " [ 686  816]]\n"
     ]
    }
   ],
   "source": [
    "# Compare criteria\n",
    "for c in ['gini', 'entropy']:\n",
    "    print(f\"\\n--- Criterion = {c} ---\")\n",
    "    m = DecisionTreeCustom(criterion=c, max_depth=6)\n",
    "    m.fit(X_train, y_train)\n",
    "    evaluate_model(m, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "632bff55-ec20-49d5-b216-4d7ba3694540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Test Accuracy: 0.8470081219956904\n",
      "Scratch Test Accuracy: 0.8468423669816012\n"
     ]
    }
   ],
   "source": [
    "# Sklearn comparison\n",
    "sk_model = SklearnDT(criterion='gini', max_depth=6, random_state=42)\n",
    "sk_model.fit(X_train, y_train)\n",
    "print('Sklearn Test Accuracy:', accuracy_score(y_test, sk_model.predict(X_test)))\n",
    "print('Scratch Test Accuracy:', accuracy_score(y_test, model_custom.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def93a9-614c-40ed-995d-cc485c374cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
